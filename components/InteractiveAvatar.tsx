/**
 * ================================================
 * InteractiveAvatar.tsx - ê²½ì˜í•™ì „ê³µ AI ê°€ì´ë“œ
 * ================================================
 *
 * ê¸°ëŠ¥:
 * 1. íƒ­ í´ë¦­ â†’ postMessage â†’ route.tsì—ì„œ ê³ ì • ìŠ¤í¬ë¦½íŠ¸ â†’ REPEAT ë°œí™”
 * 2. ìŒì„± ì§ˆë¬¸ â†’ Web Speech API â†’ OpenAI â†’ REPEAT ë°œí™”
 * 3. í…ìŠ¤íŠ¸ ì§ˆë¬¸ â†’ OpenAI â†’ REPEAT ë°œí™”
 *
 * í•µì‹¬: ì•„ë°”íƒ€ê°€ ë§í•  ë•Œ Web Speech ì¼ì‹œì •ì§€ â†’ ìê¸° ëª©ì†Œë¦¬ ì¸ì‹ ë°©ì§€
 * 
 * ğŸ”§ 2026-01-12 ìˆ˜ì •:
 * - ElevenLabs ë‹¤êµ­ì–´ ëª¨ë¸ â†’ HeyGen í•œêµ­ì–´ ì „ìš© ìŒì„± (SunHi) ë³€ê²½
 * ================================================
 */

import {
  AvatarQuality,
  StreamingEvents,
  VoiceEmotion,
  StartAvatarRequest,
  TaskType,
} from "@heygen/streaming-avatar";
import { useEffect, useRef, useState, useCallback } from "react";
import { useMemoizedFn, useUnmount } from "ahooks";

import { useStreamingAvatarSession } from "./logic/useStreamingAvatarSession";
import { StreamingAvatarProvider, StreamingAvatarSessionState } from "./logic";
import { AVATARS } from "@/app/lib/constants";
import { WebSpeechRecognizer } from "@/app/lib/webSpeechAPI";

// ì•„ë°”íƒ€ ì„¤ì • - Onyx ë‹¤êµ­ì–´ ë‚¨ì„± ìŒì„± + Wayne ì•„ë°”íƒ€ ì‚¬ìš©
const AVATAR_CONFIG: StartAvatarRequest = {
  quality: AvatarQuality.Low,
  avatarName: "Wayne_20240711",  // í•œêµ­ì¸ ë‚¨ì„± ì•„ë°”íƒ€
  voice: {
    voiceId: "26b2064088674c80b1e5fc5ab1a068ea",  // Onyx (Multilingual)
    rate: 1.0,
    emotion: VoiceEmotion.FRIENDLY,
  },
  language: "ko",
};

interface ChatMessage {
  role: "user" | "assistant";
  content: string;
}

function InteractiveAvatar() {
  const {
    initAvatar,
    startAvatar,
    stopAvatar,
    sessionState,
    stream,
    avatarRef,
  } = useStreamingAvatarSession();

  // UI ìƒíƒœ
  const [inputText, setInputText] = useState("");
  const [isLoading, setIsLoading] = useState(false);
  const [chatHistory, setChatHistory] = useState<ChatMessage[]>([]);
  const [isListening, setIsListening] = useState(false);
  const [isAvatarSpeaking, setIsAvatarSpeaking] = useState(false);
  const [interimTranscript, setInterimTranscript] = useState("");
  const [currentTab, setCurrentTab] = useState<string>("");
  const mediaStream = useRef<HTMLVideoElement>(null);

  // ë‚´ë¶€ ìƒíƒœ refs
  const isProcessingRef = useRef(false);
  const hasGreetedRef = useRef(false);
  const hasStartedRef = useRef(false);

  // Web Speech API ref
  const webSpeechRef = useRef<WebSpeechRecognizer | null>(null);
  const isAvatarSpeakingRef = useRef(false);

  // ============================================
  // API í˜¸ì¶œ
  // ============================================
  const fetchAccessToken = async () => {
    const response = await fetch("/api/get-access-token", { method: "POST" });
    const token = await response.text();
    console.log("Access Token:", token);
    return token;
  };

  // ğŸ¯ íƒ­ ì„¤ëª… API í˜¸ì¶œ (ê³ ì • ìŠ¤í¬ë¦½íŠ¸ ë°˜í™˜)
  const fetchTabScript = async (tabId: string): Promise<string> => {
    try {
      const response = await fetch("/api/chat", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          type: "tab_explain",
          tabId: tabId,
        }),
      });
      const data = await response.json();
      return data.reply || "ì„¤ëª…ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.";
    } catch (error) {
      console.error("Tab script API error:", error);
      return "ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.";
    }
  };

  // ğŸ’¬ ì¼ë°˜ ì±„íŒ… API í˜¸ì¶œ (OpenAI)
  const callOpenAI = async (message: string, history: ChatMessage[]) => {
    try {
      const response = await fetch("/api/chat", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          message: message,
          history: history,
        }),
      });
      const data = await response.json();
      console.log("ğŸ“¦ API raw response:", data);
      return data; // ì „ì²´ ê°ì²´ ë°˜í™˜ { reply, action, tabId }
    } catch (error) {
      console.error("OpenAI API error:", error);
      return { reply: "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”.", action: "none", tabId: null };
    }
  };

  // ============================================
  // ì•„ë°”íƒ€ ìŒì„± ì¶œë ¥ (Web Speech ì¼ì‹œì •ì§€ í¬í•¨)
  // ============================================
  const speakWithAvatar = useCallback(
    async (text: string) => {
      if (!avatarRef.current || !text) return;

      try {
        // ğŸ”‡ Web Speech ì™„ì „íˆ ì •ì§€
        console.log("ğŸ”‡ Web Speech ì¼ì‹œì •ì§€");
        isAvatarSpeakingRef.current = true;
        setIsAvatarSpeaking(true);
        webSpeechRef.current?.pause();

        // ì ì‹œ ëŒ€ê¸° (Web Speechê°€ ì™„ì „íˆ ë©ˆì¶œ ë•Œê¹Œì§€)
        await new Promise((r) => setTimeout(r, 300));

        // HeyGen ìë™ ì‘ë‹µ ì°¨ë‹¨
        try {
          await avatarRef.current.interrupt();
        } catch {
          // ignore
        }

        console.log("ğŸ—£ï¸ Avatar speaking:", text);
        await avatarRef.current.speak({
          text,
          taskType: TaskType.REPEAT,
        });
      } catch (error) {
        console.error("Avatar speak error:", error);
        isAvatarSpeakingRef.current = false;
        setIsAvatarSpeaking(false);
        webSpeechRef.current?.resume();
      }
    },
    [avatarRef],
  );

  // ============================================
  // ğŸ¤ ì‚¬ìš©ì ìŒì„± ì²˜ë¦¬ (Web Speech APIìš©)
  // ============================================
  const handleUserSpeech = useCallback(
    async (transcript: string) => {
      if (isAvatarSpeakingRef.current) {
        console.log("â¸ï¸ ì•„ë°”íƒ€ê°€ ë§í•˜ëŠ” ì¤‘ - ë¬´ì‹œ:", transcript);
        return;
      }

      if (!transcript.trim() || isProcessingRef.current) return;

      isProcessingRef.current = true;
      setIsLoading(true);
      setInterimTranscript("");
      console.log("ğŸ¯ User said:", transcript);

      setChatHistory((prev) => {
        const newHistory = [
          ...prev,
          { role: "user" as const, content: transcript },
        ];

        callOpenAI(transcript, prev).then(async (response) => {
          console.log("ğŸ¯ OpenAI response:", response);
          
          const reply = response.reply || response;
          const action = response.action;
          const navigateTabId = response.tabId;

          setChatHistory((current) => [
            ...current,
            { role: "assistant" as const, content: reply },
          ]);

          // ì•„ë°”íƒ€ ë°œí™”
          await speakWithAvatar(reply);

          // ğŸ¯ íƒ­ ì´ë™ ëª…ë ¹ì´ ìˆìœ¼ë©´ ë¶€ëª¨ í˜ì´ì§€ì— ì „ë‹¬
          if (action === "navigate" && navigateTabId) {
            console.log("ğŸ“‘ Navigate to tab:", navigateTabId);
            window.parent.postMessage({
              type: "NAVIGATE_TAB",
              tabId: navigateTabId
            }, "*");
          }

          setIsLoading(false);
          isProcessingRef.current = false;
        });

        return newHistory;
      });
    },
    [speakWithAvatar],
  );

  // ============================================
  // ğŸ¯ íƒ­ ë³€ê²½ ì²˜ë¦¬
  // ============================================
  const handleTabChange = useCallback(
    async (tabId: string) => {
      if (isProcessingRef.current) return;
      isProcessingRef.current = true;

      console.log("ğŸ“‘ Tab changed:", tabId);
      setCurrentTab(tabId);
      setIsLoading(true);

      // ğŸ”‡ ë¨¼ì € Web Speech ì¼ì‹œì •ì§€
      console.log("ğŸ”‡ Tab change - Web Speech ì¼ì‹œì •ì§€");
      isAvatarSpeakingRef.current = true;
      setIsAvatarSpeaking(true);
      webSpeechRef.current?.pause();

      // í˜„ì¬ ë°œí™” ì¤‘ì´ë©´ ì¤‘ë‹¨
      if (avatarRef.current) {
        try {
          await avatarRef.current.interrupt();
        } catch {
          // ignore
        }
      }

      // APIì—ì„œ ìŠ¤í¬ë¦½íŠ¸ ê°€ì ¸ì˜¤ê¸°
      const script = await fetchTabScript(tabId);

      // ì•„ë°”íƒ€ë¡œ ë°œí™” (speakWithAvatar ë‚´ë¶€ì—ì„œ ë‹¤ì‹œ pause í˜¸ì¶œí•´ë„ OK)
      if (avatarRef.current && script) {
        try {
          console.log("ğŸ—£ï¸ Avatar speaking:", script);
          await avatarRef.current.speak({
            text: script,
            taskType: TaskType.REPEAT,
          });
        } catch (error) {
          console.error("Avatar speak error:", error);
        }
      }

      setIsLoading(false);
      isProcessingRef.current = false;
    },
    [avatarRef],
  );

  // ============================================
  // Web Speech API ì´ˆê¸°í™”
  // ============================================
  const initWebSpeech = useCallback(() => {
    if (webSpeechRef.current) {
      console.log("ğŸ¤ Web Speech ì´ë¯¸ ì´ˆê¸°í™”ë¨");
      return;
    }

    if (!WebSpeechRecognizer.isSupported()) {
      console.error("ğŸ¤ Web Speech API ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €");
      alert(
        "ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. Chrome ë˜ëŠ” Edgeë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.",
      );
      return;
    }

    console.log("ğŸ¤ Web Speech API ì´ˆê¸°í™” ì¤‘...");

    webSpeechRef.current = new WebSpeechRecognizer(
      {
        onResult: (transcript: string, isFinal: boolean) => {
          if (isAvatarSpeakingRef.current) {
            return;
          }

          if (isFinal) {
            console.log("ğŸ¤ ìµœì¢… ì¸ì‹:", transcript);
            setInterimTranscript("");
            handleUserSpeech(transcript);
          } else {
            setInterimTranscript(transcript);
          }
        },

        onStart: () => {
          if (!isAvatarSpeakingRef.current) {
            setIsListening(true);
          }
        },

        onEnd: () => {
          setIsListening(false);
        },

        onSpeechStart: () => {
          if (!isAvatarSpeakingRef.current) {
            setIsListening(true);
          }
        },

        onSpeechEnd: () => {
          setTimeout(() => {
            if (!isAvatarSpeakingRef.current) {
              setIsListening(false);
            }
          }, 500);
        },

        onError: (error: string) => {
          console.error("ğŸ¤ Web Speech ì—ëŸ¬:", error);
          if (error === "not-allowed") {
            alert(
              "ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ë§ˆì´í¬ë¥¼ í—ˆìš©í•´ì£¼ì„¸ìš”.",
            );
          }
        },
      },
      {
        lang: "ko-KR",
        continuous: true,
        interimResults: true,
        autoRestart: true,
      },
    );

    console.log("ğŸ¤ Web Speech API ì´ˆê¸°í™” ì™„ë£Œ");
  }, [handleUserSpeech]);

  // ============================================
  // ì„¸ì…˜ ì´ˆê¸°í™”
  // ============================================
  const resetSession = useMemoizedFn(async () => {
    console.log("ğŸ”„ ì„¸ì…˜ ì´ˆê¸°í™” ì¤‘...");

    // Web Speech ì •ë¦¬
    if (webSpeechRef.current) {
      webSpeechRef.current.destroy();
      webSpeechRef.current = null;
    }

    // HeyGen ì„¸ì…˜ ì •ë¦¬ (ì—¬ëŸ¬ ë°©ë²• ì‹œë„)
    try {
      if (avatarRef.current) {
        await avatarRef.current.stopAvatar();
      }
    } catch (e) {
      console.log("stopAvatar ì—ëŸ¬ (ë¬´ì‹œ):", e);
    }

    try {
      await stopAvatar();
    } catch (e) {
      console.log("stopAvatar hook ì—ëŸ¬ (ë¬´ì‹œ):", e);
    }

    // ìƒíƒœ ì´ˆê¸°í™”
    hasStartedRef.current = false;
    hasGreetedRef.current = false;
    isProcessingRef.current = false;
    isAvatarSpeakingRef.current = false;
    setChatHistory([]);
    setIsLoading(false);
    setIsListening(false);
    setIsAvatarSpeaking(false);
    setInterimTranscript("");
    setCurrentTab("");

    await new Promise((r) => setTimeout(r, 1000)); // 1ì´ˆ ëŒ€ê¸°
    console.log("ğŸ”„ ì„¸ì…˜ ì´ˆê¸°í™” ì™„ë£Œ");
  });

  // ============================================
  // ì„¸ì…˜ ì‹œì‘
  // ============================================
  const startSession = useMemoizedFn(async () => {
    if (hasStartedRef.current) {
      console.log("âš ï¸ ì´ë¯¸ ì„¸ì…˜ ì‹œì‘ë¨, ë¬´ì‹œ");
      return;
    }
    hasStartedRef.current = true;

    try {
      const token = await fetchAccessToken();
      const avatar = initAvatar(token);

      avatar.on(StreamingEvents.STREAM_READY, async (event) => {
        console.log("Stream ready:", event.detail);

        if (!hasGreetedRef.current) {
          await new Promise((r) => setTimeout(r, 1500));

          const greeting =
            "ì•ˆë…•í•˜ì„¸ìš”! ì°¨ì˜ê³¼í•™ëŒ€í•™êµ ê²½ì˜í•™ì „ê³µ AI ê°€ì´ë“œì…ë‹ˆë‹¤. ê¶ê¸ˆí•œ íƒ­ì„ í´ë¦­í•˜ê±°ë‚˜, ì§ˆë¬¸ì„ ë§ì”€í•´ì£¼ì„¸ìš”!";

          console.log("ğŸ‘‹ ì¸ì‚¬ë§:", greeting);
          await speakWithAvatar(greeting);
          setChatHistory([{ role: "assistant", content: greeting }]);
          hasGreetedRef.current = true;
        }
      });

      avatar.on(StreamingEvents.STREAM_DISCONNECTED, () => {
        console.log("Stream disconnected");
        hasGreetedRef.current = false;
        hasStartedRef.current = false;

        webSpeechRef.current?.destroy();
        webSpeechRef.current = null;
      });

      avatar.on(StreamingEvents.AVATAR_START_TALKING, () => {
        console.log("ğŸ—£ï¸ Avatar started talking - Web Speech ì¼ì‹œì •ì§€");
        isAvatarSpeakingRef.current = true;
        setIsAvatarSpeaking(true);
        webSpeechRef.current?.pause();
      });

      avatar.on(StreamingEvents.AVATAR_STOP_TALKING, async () => {
        console.log("ğŸ”ˆ Avatar stopped talking - Web Speech ì¬ê°œ");
        isAvatarSpeakingRef.current = false;
        setIsAvatarSpeaking(false);

        await new Promise((r) => setTimeout(r, 500));
        webSpeechRef.current?.resume();
        console.log("ğŸ¤ Web Speech ì¬ê°œ ì™„ë£Œ");
      });

      await startAvatar(AVATAR_CONFIG);

      console.log("ğŸ¤ Web Speech API ì‹œì‘...");
      initWebSpeech();

      setTimeout(() => {
        webSpeechRef.current?.start();
        console.log("ğŸ¤ Web Speech ì¸ì‹ ì‹œì‘");
      }, 2000);
    } catch (error) {
      console.error("Session error:", error);
      hasStartedRef.current = false;
    }
  });

  // ============================================
  // í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡
  // ============================================
  const handleSendMessage = useMemoizedFn(async () => {
    const text = inputText.trim();
    if (!text || !avatarRef.current || isLoading) return;

    setInputText("");
    setIsLoading(true);

    const newHistory = [
      ...chatHistory,
      { role: "user" as const, content: text },
    ];

    setChatHistory(newHistory);

    const response = await callOpenAI(text, chatHistory);
    
    const reply = response.reply || response;
    const action = response.action;
    const navigateTabId = response.tabId;

    setChatHistory([
      ...newHistory,
      { role: "assistant" as const, content: reply },
    ]);

    await speakWithAvatar(reply);

    // ğŸ¯ íƒ­ ì´ë™ ëª…ë ¹ì´ ìˆìœ¼ë©´ ë¶€ëª¨ í˜ì´ì§€ì— ì „ë‹¬
    if (action === "navigate" && navigateTabId) {
      console.log("ğŸ“‘ Navigate to tab:", navigateTabId);
      window.parent.postMessage({
        type: "NAVIGATE_TAB",
        tabId: navigateTabId
      }, "*");
    }

    setIsLoading(false);
  });

  // ============================================
  // ë§ˆì´í¬ í† ê¸€ ë²„íŠ¼ í•¸ë“¤ëŸ¬
  // ============================================
  const toggleMicrophone = useCallback(() => {
    if (!webSpeechRef.current) {
      initWebSpeech();
      setTimeout(() => {
        webSpeechRef.current?.start();
      }, 100);
      return;
    }

    if (webSpeechRef.current.getIsPaused()) {
      webSpeechRef.current.resume();
    } else {
      webSpeechRef.current.pause();
    }
  }, [initWebSpeech]);

  // ============================================
  // postMessage í†µì‹  (ë©”ì¸ í˜ì´ì§€ì™€)
  // ============================================
  useEffect(() => {
    const handleMessage = async (event: MessageEvent) => {
      // origin ê²€ì¦ (ë³´ì•ˆ)
      const allowedOrigins = [
        "https://sdkparkforbi.github.io",
        "http://localhost",
        "http://127.0.0.1",
      ];

      const isAllowed = allowedOrigins.some((origin) =>
        event.origin.startsWith(origin)
      );

      if (!isAllowed) {
        console.log("âš ï¸ Ignored message from:", event.origin);
        return;
      }

      const { type, tabId } = event.data || {};
      console.log("ğŸ“¥ Received message:", { type, tabId, origin: event.origin });

      if (type === "TAB_CHANGED" && tabId) {
        handleTabChange(tabId);
      }
    };

    window.addEventListener("message", handleMessage);
    return () => window.removeEventListener("message", handleMessage);
  }, [handleTabChange]);

  // ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  useUnmount(() => {
    webSpeechRef.current?.destroy();

    try {
      stopAvatar();
    } catch {
      // ignore
    }
  });

  // ============================================
  // ğŸ”„ í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨/ë‹«ê¸° ì „ ì„¸ì…˜ ì •ë¦¬
  // ============================================
  useEffect(() => {
    const handleBeforeUnload = () => {
      console.log("ğŸ”„ beforeunload - ì„¸ì…˜ ì •ë¦¬ ì¤‘...");
      
      // Web Speech ì •ë¦¬
      if (webSpeechRef.current) {
        webSpeechRef.current.destroy();
        webSpeechRef.current = null;
      }
      
      // HeyGen ì„¸ì…˜ ì •ë¦¬
      if (avatarRef.current) {
        try {
          avatarRef.current.stopAvatar();
        } catch {
          // ignore
        }
      }
    };

    window.addEventListener("beforeunload", handleBeforeUnload);
    
    return () => {
      window.removeEventListener("beforeunload", handleBeforeUnload);
    };
  }, [avatarRef]);

  // ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì—°ê²°
  useEffect(() => {
    if (stream && mediaStream.current) {
      mediaStream.current.srcObject = stream;
      mediaStream.current.onloadedmetadata = () => mediaStream.current?.play();
    }
  }, [stream]);

  // ============================================
  // UI
  // ============================================
  const getStatusText = () => {
    if (isAvatarSpeaking) return "ì„¤ëª… ì¤‘...";
    if (isListening) return "ë“£ëŠ” ì¤‘...";
    if (isLoading) return "ìƒê° ì¤‘...";
    return "ë§ì”€í•˜ì„¸ìš”";
  };

  const getStatusColor = () => {
    if (isAvatarSpeaking) return "bg-blue-500";
    if (isListening) return "bg-red-500 animate-pulse";
    if (isLoading) return "bg-yellow-500";
    return "bg-green-500";
  };

  return (
    <div className="w-full h-full flex flex-col">
      {sessionState === StreamingAvatarSessionState.CONNECTED && stream ? (
        <div className="flex-1 relative flex flex-col">
          <div className="relative flex-shrink-0">
            <video
              ref={mediaStream}
              autoPlay
              playsInline
              style={{ display: "block", width: "100%", height: "auto" }}
            />

            {/* ì¢…ë£Œ ë²„íŠ¼ */}
            <button
              className="absolute top-2 right-2 w-7 h-7 bg-black/50 hover:bg-red-600 text-white rounded-full flex items-center justify-center text-xs"
              onClick={() => resetSession()}
            >
              âœ•
            </button>

            {/* ë§ˆì´í¬ í† ê¸€ ë²„íŠ¼ */}
            <button
              className={`absolute top-2 left-2 w-7 h-7 ${
                isListening
                  ? "bg-red-500 animate-pulse"
                  : "bg-black/50 hover:bg-green-600"
              } text-white rounded-full flex items-center justify-center text-sm`}
              disabled={isAvatarSpeaking}
              title={isListening ? "ë§ˆì´í¬ ë„ê¸°" : "ë§ˆì´í¬ ì¼œê¸°"}
              onClick={toggleMicrophone}
            >
              {isListening ? "ğŸ¤" : "ğŸ™ï¸"}
            </button>

            {/* ìƒíƒœ í‘œì‹œ */}
            <div className="absolute bottom-2 left-2 flex items-center gap-2">
              <div className={`w-3 h-3 rounded-full ${getStatusColor()}`} />
              <span className="text-white text-xs bg-black/50 px-2 py-1 rounded">
                {getStatusText()}
              </span>
            </div>

            {/* í˜„ì¬ íƒ­ í‘œì‹œ */}
            {currentTab && (
              <div className="absolute bottom-2 right-2">
                <span className="text-white text-xs bg-purple-600/80 px-2 py-1 rounded">
                  ğŸ“‘ {currentTab}
                </span>
              </div>
            )}

            {/* ì¤‘ê°„ ì¸ì‹ ê²°ê³¼ í‘œì‹œ */}
            {interimTranscript && (
              <div className="absolute bottom-10 left-2 right-2">
                <div className="bg-black/70 text-white text-xs px-2 py-1 rounded">
                  ğŸ¤ &quot;{interimTranscript}&quot;
                </div>
              </div>
            )}
          </div>

          {/* í…ìŠ¤íŠ¸ ì…ë ¥ */}
          <div className="p-2 bg-zinc-800 border-t border-zinc-700">
            <div className="flex gap-2">
              <input
                className="flex-1 px-3 py-2 bg-zinc-700 text-white text-sm rounded-lg border border-zinc-600 focus:outline-none focus:border-purple-500 disabled:opacity-50"
                disabled={isLoading || isAvatarSpeaking}
                placeholder="ë˜ëŠ” í…ìŠ¤íŠ¸ë¡œ ì§ˆë¬¸í•˜ì„¸ìš”..."
                type="text"
                value={inputText}
                onChange={(e) => setInputText(e.target.value)}
                onKeyDown={(e) =>
                  e.key === "Enter" && !e.shiftKey && handleSendMessage()
                }
              />
              <button
                className="px-4 py-2 bg-purple-600 hover:bg-purple-700 disabled:bg-zinc-600 text-white text-sm rounded-lg"
                disabled={isLoading || isAvatarSpeaking || !inputText.trim()}
                onClick={handleSendMessage}
              >
                {isLoading ? "..." : "ì „ì†¡"}
              </button>
            </div>
          </div>
        </div>
      ) : (
        <div className="w-full h-full flex items-center justify-center">
          {sessionState === StreamingAvatarSessionState.CONNECTING ? (
            <div className="flex flex-col items-center gap-3 text-white">
              <div className="w-8 h-8 border-2 border-purple-500 border-t-transparent rounded-full animate-spin" />
              <span className="text-sm">ì—°ê²° ì¤‘...</span>
            </div>
          ) : (
            <button
              className="px-6 py-3 bg-purple-600 hover:bg-purple-700 text-white rounded-full text-base font-medium shadow-lg"
              onClick={startSession}
            >
              ğŸ“ AI ê°€ì´ë“œ ì‹œì‘
            </button>
          )}
        </div>
      )}
    </div>
  );
}

export default function InteractiveAvatarWrapper() {
  return (
    <StreamingAvatarProvider basePath={process.env.NEXT_PUBLIC_BASE_API_URL}>
      <InteractiveAvatar />
    </StreamingAvatarProvider>
  );
}
